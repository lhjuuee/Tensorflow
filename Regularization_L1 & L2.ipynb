{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "Deep neural network normally has tens of thousands of parameters, sometime millons of parameters.\n",
    "\n",
    "Due to this, network has high number of degree of freedom. It makes model be able to learn\n",
    "\n",
    "complex dataset. But it means deep neural network prones to overfitting. By **regularization**,\n",
    "\n",
    "we can ease this problem.\n",
    "\n",
    "## 1. L1 & L2 regularization\n",
    "As it apply to linear regression, it can regularize weights on network. \n",
    "\n",
    "By adding L1 or L2 norm on weights and finally adding on loss function, we can give penalty to\n",
    "\n",
    "weights in order to prevent overfitting. And there is another **hyperparameter** alpha to tune how strong\n",
    "\n",
    "the regularization is on loss function.Basically, L1 uses abolute value of w and L2 uses square\n",
    "\n",
    "value of w, diveded by 1/2.(to simplify calculation of differentiation)\n",
    "\n",
    "##### In TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscale = 0.001 # hyperparameter\\nmy_dense_layer = partial(\\n    tf.layers.dense, activation=tf.nn.relu, kernel_regularizer=tf.contrib.layers.l1_regularizer(scale))\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "scale = 0.001 # hyperparameter\n",
    "my_dense_layer = partial(\n",
    "    tf.layers.dense, activation=tf.nn.relu, kernel_regularizer=tf.contrib.layers.l1_regularizer(scale))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith tf.name_scope(\\'dnn\\'):\\n    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\\n    hidden2 = my_dense_layer(hidden1, n_hidden2, name=\"hidden2\")\\n    logits = my_dense_layer(hidden2, n_outputs, activation=None, name=\"outputs\")\\n    \\n    \\n# Tensorflow automatically adds all regularization in COLLECTION\\n    \\nreg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\\nloss = tf.add_n([base_loss] + reg_losses, name=\"loss\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    hidden2 = my_dense_layer(hidden1, n_hidden2, name=\"hidden2\")\n",
    "    logits = my_dense_layer(hidden2, n_outputs, activation=None, name=\"outputs\")\n",
    "    \n",
    "    \n",
    "# Tensorflow automatically adds all regularization in COLLECTION\n",
    "    \n",
    "reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "loss = tf.add_n([base_loss] + reg_losses, name=\"loss\")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
