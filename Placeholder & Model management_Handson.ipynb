{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder & Model management_Handson\n",
    "\n",
    "## 1. Placeholder\n",
    "\n",
    "For using mini-batch gradient descent, we have to change X, y at every iteration. To avoid this, we can use placeholder.\n",
    "\n",
    "This node doesn't calculate anything and exists just for delivering data to train.\n",
    "\n",
    "After making placeholder to deliver data, feed data by feed_dict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda_\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n",
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A:[[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A:[[4, 5, 6], [7, 8, 9]]})\n",
    "    \n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In mini-batch\n",
    "\n",
    "To realize mini-batch gradient descent first, define X, y as place holder and then batch size and batch number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\\ny = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\\n\\nbatch_size = 100\\nn_batches = int(np.ceil(m / batch_size))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code m means number of samples and shape means data size of input and output.\n",
    "\n",
    "#### How to realize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef fetch_batch(epoch, batch_index, batch_size):\\n    [...] # data load\\n    return X_batch, y_batch\\n\\nwith tf.Session() as sess:\\n    sess.run(init)\\n    \\n    for epoch in range(n_epochs):\\n        for batch_index in range(n_batches):\\n            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\\n            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\\n            \\n    best_theta = theta.eval()\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    [...] # data load\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "    best_theta = theta.eval()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Management\n",
    "\n",
    "### 2.1 Save\n",
    "\n",
    "After training model, parameters have to be saved to reuse. Or during training, we can make 'checkpoint' by saving model.\n",
    "\n",
    "It is easy to save in tensor flow.\n",
    "\n",
    "At last, add Saver node and when you want to save model during execution, call save() method delivering route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n[...]\\ntheta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name = \\'theta\\')\\n[...]\\ninit = tf.global_variables_initializer()\\nsaver = tf.train.Saver()\\n\\nwith tf.Session() as sess:\\n    sess.run(init)\\n    \\n    for epoch in range(n_epochs):\\n        if epoch % 100 == 0:\\n            save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\\n            \\n        sess.run(training_op)\\n    \\n    best_theta = theta.eval()\\n    save_path = saver.save(sess, \"/tmp/mymodel_final.ckpt\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "[...]\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name = 'theta')\n",
    "[...]\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
    "            \n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"/tmp/mymodel_final.ckpt\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Restore\n",
    "\n",
    "As save operated, it has same process. Add Saver node and call restore() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith tf.Session() as sess:\\n    saver.restore(sess, \"/tmp/my_model_final.ckpt\")\\n    [...]\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    [...]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saver, at base, saves and restores all variables. And we can name to those as another name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saver = tf.train.Saver({\"weights\": theta})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
